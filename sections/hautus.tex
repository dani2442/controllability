\section{Data-Driven Hautus Tests for Continuous-Time Systems}
\label{sec:hautus}
One route to certifying controllability (more precisely, the dimension of the controllable subspace) from data is via terminal-state information under structural assumptions (e.g., a fixed initial condition and structured input families).
Here we develop an alternative route based on rank conditions that are equivalent to controllability/stabilizability.
For continuous-time LTI systems \eqref{eq:lti}, the classical Hautus (PBH) test \cite[Theorem~3.13]{trentelmanControlTheoryLinear2001} states:
\begin{itemize}
  \item $(\mat{A},\mat{B})$ is controllable if and only if $\operatorname{rank}\begin{bmatrix}\mat{A}-\lambda \mat{I} & \mat{B}\end{bmatrix}=n$ for all $\lambda\in\CC$;
  \item $(\mat{A},\mat{B})$ is stabilizable if and only if $\operatorname{rank}\begin{bmatrix}\mat{A}-\lambda \mat{I} & \mat{B}\end{bmatrix}=n$ for all $\lambda\in\CC$ with $\Re(\lambda)\ge 0$.
\end{itemize}
%
Using only measured data, one can test controllability/stabilizability without explicitly identifying $(\mat{A},\mat{B})$; see \cite{vanwaardeDataInformativityNew2020,iannelliDesignInputDatadriven2021} for the discrete-time case.
Here we state a continuous-time version based on time-domain moments of the state and input signals.
\paragraph{Data model.}
We assume access to $u(\cdot)$ and the resulting state $x(\cdot)$ on a finite horizon $[0,T]$ (either as a continuous-time record or via sufficiently fine sampling so that the integrals below can be approximated numerically).
When $\dot x$ is not directly available or is too noisy to estimate reliably, we rely on the cross-moment formulation in Section~\ref{subsec:hautus-ito}, which only uses increments of $x$ in the stochastic setting and avoids forming $\dot x$ in the deterministic setting.

\paragraph{Outline.}
We first introduce a residual Gramian $\mat{G}_\lambda(u)$ whose invertibility for all $\lambda\in\CC$ is equivalent to controllability under a mild data-richness condition.
We then develop a derivative-free cross-moment formulation (deterministic and It\^o) that enables estimating $\mat{G}_\lambda(u)$ and a corresponding Hautus margin directly from measured data.
Finally, we give an operator formulation that reduces checking all $\lambda\in\CC$ to a finite candidate set and discuss a simple $L^2$-budget design principle for conditioning the input Gramian.

\subsection{Time-domain Gramian formulation}
\label{subsec:hautus-time-domain}

For input design it is convenient to work with a continuous-time analogue in which rank is replaced by a coercive quadratic functional.

Fix a horizon $T>0$ and let $u\in L^2(0,T;\R^m)$ be an input generating an absolutely continuous state trajectory $x:[0,T]\to\R^n$ with $x,\dot x\in L^2(0,T;\R^n)$.
For $\lambda\in\CC$ define the residual signal and its (time-domain) Gramian
\[
  m_\lambda(t):=\dot x(t)-\lambda x(t)\in\CC^n,
  \qquad
  \mat{G}_\lambda(u):=\int_0^T m_\lambda(t)m_\lambda(t)^*\,\d t\in\CC^{n\times n}.
\]

Define the stacked signal and its Gramian
\[
  z(t):=\begin{bmatrix}x(t)\\u(t)\end{bmatrix}\in\R^{n+m},
  \qquad
  \mat{S}_Z(u):=\int_0^T z(t)z(t)^\top\,\d t\in\R^{(n+m)\times(n+m)}.
\]
Finally, define the Hautus matrix
\[
  \mat{P}_\lambda := \begin{bmatrix}\mat{A}-\lambda \mat{I} & \mat{B}\end{bmatrix}\in\CC^{n\times(n+m)}.
\]
Note that $\mat{S}_Z(u)\succeq 0$ and $\mat{G}_\lambda(u)\succeq 0$ by construction. Moreover, for every admissible input $u$,
\[
  m_\lambda(t)=(\mat{A}-\lambda \mat{I})x(t)+\mat{B}u(t)=\mat{P}_\lambda z(t)\quad\text{for a.e.\ }t\in(0,T),
\]
and therefore
\begin{equation}\label{eq:hautus-continuous-factorization}
  \mat{G}_\lambda(u)=\mat{P}_\lambda \mat{S}_Z(u) \mat{P}_\lambda^*.
\end{equation}

\paragraph{Frequency-domain representation.}
To relate this to a Fourier-domain statistic, view $m_\lambda$ as a time-limited signal extended by zero outside $[0,T]$.
That is, define $\tilde m_\lambda(t):=m_\lambda(t)\mathds{1}_{[0,T]}(t)$ and its Fourier transform by
\[
  \widehat m_\lambda(\ii\omega):=\int_{\R} \tilde m_\lambda(t)e^{-\ii\omega t}\,\d t=\int_0^T m_\lambda(t)e^{-\ii\omega t}\,\d t,\qquad \omega\in\R.
\]
By the Plancherel theorem (Parseval identity) with this convention,
\begin{equation}\label{eq:hautus-parseval-m}
  \mat{G}_\lambda(u)=\int_{\R} \widehat m_\lambda(\ii\omega)\widehat m_\lambda(\ii\omega)^*\,\frac{\d\omega}{2\pi}.
\end{equation}
This yields a direct frequency-domain analogue of the time-domain margin $\sigma_{\min}(\mat{G}_\lambda(u))$.
In practice, one evaluates $\sigma_{\min}(\mat{G}_\lambda(u))$ on a finite set of $\lambda$ (e.g., a grid or the candidate values discussed below).
Working with $\widehat m_\lambda$ directly avoids integration-by-parts boundary terms.
Indeed, for $\widehat x(\ii\omega):=\int_0^T x(t)e^{-\ii\omega t}\,\d t$,
integration by parts gives
\[
  \int_0^T \dot x(t)e^{-\ii\omega t}\,\d t = x(T)e^{-\ii\omega T}-x(0)+ \ii\omega\widehat x(\ii\omega),
\]
hence
\[
  \widehat m_\lambda(\ii\omega) = (\ii\omega-\lambda)\widehat x(\ii\omega) + x(T)e^{-\ii\omega T} - x(0).
\]
Fix $v\in\CC^n$. Since  $\mat{P}_\lambda\mat{S}_Z(u)\mat{P}_\lambda^*\succeq 0$ and $\mat{S}_Z(u)\succeq 0$,
\[
  v^*\mat{P}_\lambda\mat{S}_Z(u)\mat{P}_\lambda^*v = (\mat{P}_\lambda^*v)^*\mat{S}_Z(u)(\mat{P}_\lambda^*v) \ge \sigma_{\min}(\mat{S}_Z(u))\,\|\mat{P}_\lambda^*v\|_2^2.
\]
By definition of $\sigma_{\min}$, $\|\mat{P}_\lambda^*v\|_2\ge \sigma_{\min}(\mat{P}_\lambda^*)\|v\|_2=\sigma_{\min}(\mat{P}_\lambda)\|v\|_2$.
Taking the minimum over $\|v\|_2=1$ and using \eqref{eq:hautus-continuous-factorization} yields
\[
  \sigma_{\min}\big(\mat{G}_\lambda(u)\big) = \sigma_{\min}(\mat{P}_\lambda\mat{S}_Z(u)\mat{P}_\lambda^*)
  \ge
  \sigma_{\min}(\mat{P}_\lambda)^2\,\sigma_{\min}\big(\mat{S}_Z(u)\big).
\]
This bound holds for every $\lambda\in\CC$.


\begin{thm}[Continuous Hautus Test]\label{thm:hautus-margin-necessary}
  If there exists $u$ such that $\operatorname{rank}(\mat{G}_\lambda(u))=n$ for all $\lambda\in\CC$, then $(\mat{A},\mat{B})$ is controllable.
  Moreover, if $\mat{S}_Z(u)$ is invertible, then the converse holds
  \[
    (\mat{A},\mat{B}) \text{ is controllable}\quad\Leftrightarrow\quad
    \operatorname{rank}(\mat{G}_\lambda(u))=n \text{ for all } \lambda\in\CC.
  \]
\end{thm}
\begin{proof}
  If $(\mat{A},\mat{B})$ is not controllable, then by the (continuous-time) Hautus test there exist $\lambda\in\CC$ and $v\neq 0$ such that $v^*\mat{P}_\lambda=0$.
  Using \eqref{eq:hautus-continuous-factorization}, this gives
  $v^*\mat{G}_\lambda(u)v = v^*\mat{P}_\lambda \mat{S}_Z(u)\mat{P}_\lambda^* v = 0$, hence $\sigma_{\min}(\mat{G}_\lambda(u))=0$.

  Conversely, assume $(\mat{A},\mat{B})$ is controllable and $\mat{S}_Z(u)$ is invertible. Then $\mat{P}_\lambda$ has full row rank for every $\lambda\in\CC$, so \eqref{eq:hautus-continuous-factorization} implies $\mat{G}_\lambda(u)\succ 0$ for every $\lambda$.
  Moreover, since $\mat{S}_Z(u)\succ 0$, its state block
  $\mat{S}_X:=\int_0^T x(t)x(t)^\top\,\d t$ satisfies $\mat{S}_X\succ 0$.
  Set $\mat{S}_{\dot X}:=\int_0^T \dot x(t)\dot x(t)^\top\,\d t$.
  For any unit $v\in\CC^n$,
  \[
    v^*\mat{G}_\lambda(u)v
    =\big\|\dot x(\cdot)^*v-\overline{\lambda}\,x(\cdot)^*v\big\|_{L^2(0,T)}^2
    \ge \Big(|\lambda|\|x(\cdot)^*v\|_{L^2(0,T)}-\|\dot x(\cdot)^*v\|_{L^2(0,T)}\Big)^2.
  \]
  Using $\|x(\cdot)^*v\|_{L^2(0,T)}^2=v^* \mat{S}_X v\ge \lambda_{\min}(\mat{S}_X)$ and
  $\|\dot x(\cdot)^*v\|_{L^2(0,T)}^2=v^* \mat{S}_{\dot X} v\le \lambda_{\max}(\mat{S}_{\dot X})$ yields the uniform lower bound
  \[
    \sigma_{\min}(\mat{G}_\lambda(u))\ge \Big(|\lambda|\sqrt{\lambda_{\min}(\mat{S}_X)}-\sqrt{\lambda_{\max}(\mat{S}_{\dot X})}\Big)^2,
  \]
  hence $\sigma_{\min}(\mat{G}_\lambda(u))\to\infty$ as $|\lambda|\to\infty$.
  Since $\lambda\mapsto \sigma_{\min}(\mat{G}_\lambda(u))$ is continuous and strictly positive, it attains a positive minimum on a large enough closed ball in $\CC$, and the coercivity above controls the complement. Therefore $\inf_{\lambda\in\CC}\sigma_{\min}(\mat{G}_\lambda(u))>0$.
\end{proof}




\subsection{Stochastic model and It\^o residual}
\label{subsec:hautus-ito}

Another alternative to direct state-derivative measurements is to estimate $\mat{P}_\lambda$, and hence $\mat{G}_\lambda(u)$, from cross-moments between the state and input signals, using only increments of $x$.
This is particularly natural in a stochastic setting, where $\dot x$ does not exist pointwise.
Assume that the measured state is an It\^o process satisfying the linear SDE
\begin{equation*}
  \d x(t)=\big(\mat{A}x(t)+\mat{B}u(t)\big)\,\d t+\beta\,\d W(t),\qquad t\in[0,T],
\end{equation*}
where $W$ is a $q$-dimensional standard Brownian motion and $\beta\in\R^{n\times q}$ is constant.
For $\lambda\in\CC$, define the It\^o residual differential
\begin{equation}\label{eq:hautus-ito-residual}
  \d y_\lambda(t):=\d x(t)-\lambda x(t)\,\d t=\mat{P}_\lambda z(t)\,\d t+\beta\,\d W(t).
\end{equation}

\paragraph{Cross-moment factorization.}
Define the (matrix-valued) cross-moment
\begin{equation}\label{eq:hautus-cross-moment-H}
  \mat{H}_\lambda(T)
  :=
  \int_0^T \d y_\lambda(t)\,z(t)^\top
  \in\CC^{n\times(n+m)},
\end{equation}
and recall $\mat{S}_Z(u)=\int_0^T z(t)z(t)^\top\,\d t$.
Plugging \eqref{eq:hautus-ito-residual} into \eqref{eq:hautus-cross-moment-H} yields the exact decomposition
\begin{equation}\label{eq:hautus-cross-moment-factorization}
  \mat{H}_\lambda(T)
  =
  \mat{P}_\lambda \mat{S}_Z(u)
  +
  \beta\int_0^T \d W(t)\,z(t)^\top.
\end{equation}
The last term is a matrix-valued martingale with $\E[\int_0^T \d W(t)\,z(t)^\top]=0$, hence $\mat{H}_\lambda(T)-\mat{P}_\lambda\mat{S}_Z(u)$ has zero mean.

\paragraph{Deterministic identity and a derivative-free margin.}
If $x$ is absolutely continuous and $\beta=0$, then $\d y_\lambda(t)=m_\lambda(t)\,\d t$ and therefore
\begin{equation}\label{eq:hautus-cross-moment-deterministic}
  \mat{H}_\lambda(T)
  =
  \int_0^T m_\lambda(t)\,z(t)^\top\,\d t
  =
  \mat{P}_\lambda \mat{S}_Z(u).
\end{equation}
If moreover $\mat{S}_Z(u)$ is invertible, then the continuous-time Gramian admits the fully derivative-free representation
\begin{equation}\label{eq:hautus-cross-moment-G-from-H}
  \mat{G}_\lambda(u)=\mat{H}_\lambda(T)\mat{S}_Z(u)^{-1}\mat{H}_\lambda(T)^*,
\end{equation}
and
\begin{equation}\label{eq:hautus-cross-moment-margin}
  \sigma_{\min}\big(\mat{G}_\lambda(u)\big)
  =
  \sigma_{\min}\!\big(\mat{H}_\lambda(T)\mat{S}_Z(u)^{-1/2}\big)^2
  \ge
  \sigma_{\min}(\mat{P}_\lambda)^2\,\sigma_{\min}\!\big(\mat{S}_Z(u)\big),
\end{equation}
where $\mat{S}_Z(u)^{-1/2}$ denotes the unique symmetric square root of $\mat{S}_Z(u)^{-1}$.

\begin{cor}[Continuous Hautus test via cross-moments]\label{cor:hautus-cross-moment-test}
  Assume $x$ is absolutely continuous, $\beta=0$, and $\mat{S}_Z(u)$ is invertible.
  Then $(\mat{A},\mat{B})$ is controllable if and only if $\operatorname{rank}(\mat{H}_\lambda(T))=n$ for all $\lambda\in\CC$.
  Equivalently,
  \[
    (\mat{A},\mat{B})\ \text{controllable}
    \quad\Longleftrightarrow\quad
    \inf_{\lambda\in\CC}\sigma_{\min}\!\big(\mat{H}_\lambda(T)\mat{S}_Z(u)^{-1/2}\big)>0.
  \]
\end{cor}
\begin{proof}
  Under the stated assumptions, \eqref{eq:hautus-cross-moment-deterministic} holds, hence
  $\mat{H}_\lambda(T)\mat{S}_Z(u)^{-1/2}=\mat{P}_\lambda \mat{S}_Z(u)^{1/2}$ and
  $\mat{G}_\lambda(u)=\big(\mat{H}_\lambda(T)\mat{S}_Z(u)^{-1/2}\big)\big(\mat{H}_\lambda(T)\mat{S}_Z(u)^{-1/2}\big)^*$.
  Therefore $\operatorname{rank}(\mat{H}_\lambda(T))=n$ for all $\lambda$ if and only if $\mat{G}_\lambda(u)\succ 0$ for all $\lambda$.
  The claim then follows from Theorem~\ref{thm:hautus-margin-necessary}.
\end{proof}

\paragraph{Estimating \texorpdfstring{$\mat{P}_\lambda$}{P\_lambda}.}
Assume that $\mat{S}_Z(u)$ is invertible and define
\begin{equation}\label{eq:hautus-cross-moment-P-hat}
  \widehat{\mat{P}}_\lambda(T):=\mat{H}_\lambda(T)\mat{S}_Z(u)^{-1}.
\end{equation}
Then \eqref{eq:hautus-cross-moment-factorization} implies the exact error identity
\begin{equation}\label{eq:hautus-cross-moment-error}
  \widehat{\mat{P}}_\lambda(T)-\mat{P}_\lambda
  =
  \beta\left(\int_0^T \d W(t)\,z(t)^\top\right)\mat{S}_Z(u)^{-1}.
\end{equation}
% Moreover, defining $\widehat{\mat{G}}_\lambda(T):=\widehat{\mat{P}}_\lambda(T)\mat{S}_Z(u)\widehat{\mat{P}}_\lambda(T)^*$, we obtain the fully data-dependent representation $\widehat{\mat{G}}_\lambda(T)=\mat{H}_\lambda(T)\mat{S}_Z(u)^{-1}\mat{H}_\lambda(T)^*$.

\paragraph{A basic \texorpdfstring{$T^{-1/2}$}{T\textasciicircum-1/2} rate via It\^o isometry.}
Introduce the normalized quantities $\bar{\mat{S}}_Z(T):=\frac{1}{T}\mat{S}_Z(u)$ and $\bar{\mat{H}}_\lambda(T):=\frac{1}{T}\mat{H}_\lambda(T)$ so that $\widehat{\mat{P}}_\lambda(T)=\bar{\mat{H}}_\lambda(T)\bar{\mat{S}}_Z(T)^{-1}$.
The It\^o isometry yields (componentwise) the bound
\begin{equation}\label{eq:hautus-cross-moment-ito-isometry}
  \E\left\|\frac{1}{T}\int_0^T \d W(t)\,z(t)^\top\right\|_F^2
  =
  \frac{q}{T^2}\E\left[\int_0^T \|z(t)\|_2^2\,\d t\right].
\end{equation}
If $\E[\int_0^T \|z(t)\|_2^2\,\d t]=\mathcal{O}(T)$ and $\|\bar{\mat{S}}_Z(T)^{-1}\|_2=\mathcal{O}_{\mathbb{P}}(1)$, then \eqref{eq:hautus-cross-moment-error} and \eqref{eq:hautus-cross-moment-ito-isometry} imply
\begin{equation}\label{eq:hautus-cross-moment-rate}
  \|\widehat{\mat{P}}_\lambda(T)-\mat{P}_\lambda\|_2=\mathcal{O}_{\mathbb{P}}(T^{-1/2}).
\end{equation}
The $\mathcal{O}_{\mathbb{P}}(T^{-1/2})$ statement above can be strengthened to an explicit bound holding with probability $1-\delta$ and depending only on the (random) conditioning of $\bar{\mat{S}}_Z(T)$.
\begin{prop}[Cross-moment error bound]\label{prop:hautus-cross-moment-high-prob}
  Assume that $\mat{S}_Z(u)\succ 0$. Then for every $\delta\in(0,1)$, with probability at least $1-\delta$,
  \begin{equation}\label{eq:hautus-cross-moment-high-prob}
    \|\widehat{\mat{P}}_\lambda(T)-\mat{P}_\lambda\|_2
    \le
    \frac{\|\beta\|_2}{\sqrt{T\,\sigma_{\min}(\bar{\mat{S}}_Z(T))}}
    \Big(\sqrt{q}+\sqrt{n+m}+\sqrt{2\log(1/\delta)}\Big).
  \end{equation}
  Moreover, this implies the uniform bound $\sup_{\lambda\in\CC}\|\widehat{\mat{P}}_\lambda(T)-\mat{P}_\lambda\|_2$ since the right-hand side of \eqref{eq:hautus-cross-moment-error} does not depend on $\lambda$.
\end{prop}
\begin{proof}
  Let $\mat{M}(T):=\int_0^T \d W(t)\,z(t)^\top\in\R^{q\times (n+m)}$. Conditional on the path $\{z(t)\}_{t\in[0,T]}$, $\mat{M}(T)$ is a centered Gaussian matrix whose rows are independent and satisfy
  \[
    \E\big[\mat{M}(T)_{i,:}^\top \mat{M}(T)_{i,:}\mid z\big] = \int_0^T z(t)z(t)^\top\,\d t = \mat{S}_Z(u),\qquad i=1,\dots,q.
  \]
  Therefore, conditional on $z$, we have the distributional identity $\mat{M}(T)\stackrel{d}{=}\mat{G}\mat{S}_Z(u)^{1/2}$ where $\mat{G}\in\R^{q\times (n+m)}$ has i.i.d.\ $\mathcal{N}(0,1)$ entries.
  Using \eqref{eq:hautus-cross-moment-error},
  \[
    \widehat{\mat{P}}_\lambda(T)-\mat{P}_\lambda
    \stackrel{d}{=}
    \beta\,\mat{G}\mat{S}_Z(u)^{-1/2},
  \]
  conditional on $z$, hence
  \[
    \|\widehat{\mat{P}}_\lambda(T)-\mat{P}_\lambda\|_2
    \le
    \frac{\|\beta\|_2}{\sqrt{\sigma_{\min}(\mat{S}_Z(u))}}\;\|\mat{G}\|_2.
  \]
  The standard Gaussian matrix bound $\mathbb{P}\big(\|\mat{G}\|_2\ge \sqrt{q}+\sqrt{n+m}+t\big)\le e^{-t^2/2}$ (valid for all $t\ge 0$; see, e.g., \cite{vershyninIntroductionApplicationsData}) yields \eqref{eq:hautus-cross-moment-high-prob} by choosing $t=\sqrt{2\log(1/\delta)}$ and using $\sigma_{\min}(\mat{S}_Z(u))=T\sigma_{\min}(\bar{\mat{S}}_Z(T))$.
\end{proof}
Finally, by Weyl's inequality,
\[
  \big|\sigma_{\min}\big(\widehat{\mat{P}}_\lambda(T)\big)-\sigma_{\min}(\mat{P}_\lambda)\big|
  \le
  \|\widehat{\mat{P}}_\lambda(T)-\mat{P}_\lambda\|_2,
\]
which provides a simple statistical analogue of the deterministic Hautus margin. In particular, Proposition~\ref{prop:hautus-cross-moment-high-prob} yields a corresponding $(1-\delta)$ bound on the singular-value deviation.


\paragraph{A Fourier-domain approximation without derivatives.}
The cross-moment $\mat{H}_\lambda(T)$ in \eqref{eq:hautus-cross-moment-H} can also be approximated in the frequency domain without forming $\dot x$.
For each $\omega\in\R$, define the Fourier transform of the residual increment
\begin{equation*}
  \widehat{dy}_\lambda(\ii\omega)
  :=
  \int_0^T e^{-\ii\omega t}\,\d y_\lambda(t)
  =
  \int_0^T e^{-\ii\omega t}\,\d x(t)-\lambda\widehat x(\ii\omega),
  \qquad
  \widehat x(\ii\omega):=\int_0^T x(t)e^{-\ii\omega t}\,\d t.
\end{equation*}
Since $t\mapsto e^{-\ii\omega t}$ is of bounded variation, It\^o integration by parts yields
\[
  \int_0^T e^{-\ii\omega t}\,\d x(t)
  =
  x(T)e^{-\ii\omega T}-x(0)+\ii\omega\int_0^T x(t)e^{-\ii\omega t}\,\d t,
\]
hence
\begin{equation}\label{eq:hautus-fourier-y}
  \widehat{dy}_\lambda(\ii\omega)
  =
  x(T)e^{-\ii\omega T}-x(0)+(\ii\omega-\lambda)\widehat x(\ii\omega).
\end{equation}
Thus, $\widehat{dy}_\lambda(\ii\omega)$ can be computed from an FFT of $x$ plus the boundary terms $x(0),x(T)$.
Define also $\widehat z(\ii\omega):=\int_0^T z(t)e^{-\ii\omega t}\,\d t$.
If $x$ is absolutely continuous so that $\d y_\lambda(t)=m_\lambda(t)\,\d t$, then Parseval gives
\[
  \mat{H}_\lambda(T)=\int_{\R}\widehat{ dy}_\lambda(\ii\omega)\widehat z(\ii\omega)^*\,\frac{\d\omega}{2\pi},
  \qquad
  \mat{S}_Z(u)=\int_{\R}\widehat z(\ii\omega)\widehat z(\ii\omega)^*\,\frac{\d\omega}{2\pi}.
\]
In the It\^o setting, the unwindowed energy $\int_{\R}\|\widehat{dy}_\lambda(\ii\omega)\|_2^2\,\d\omega$ is not finite (it corresponds to the $L^2$-energy of a derivative that does not exist), so frequency-domain computations should be interpreted with an explicit cutoff/windowing when needed.



\subsection{An operator formulation and finitely many candidate \texorpdfstring{$\lambda$}{lambda}}
\label{subsec:hautus-operator}
The main inconvenience of Theorem~\ref{thm:hautus-margin-necessary} is that the margin condition must hold for all $\lambda\in\CC$.
To address this, we now develop an operator formulation that allows us to identify finitely many candidate $\lambda$ where rank failure can occur.
%
Let $x:[0,T]\to\R^n$ be absolutely continuous with $x,\dot x\in L^2(0,T;\R^n)$ and define operators
\[
  \X,\dot\X:L^2(0,T)\to\CC^n,\qquad
  \X(\varphi):=\int_0^T x(t)\varphi(t)\,\d t,\quad
  \dot\X(\varphi):=\int_0^T \dot x(t)\varphi(t)\,\d t.
\]
For $\lambda\in\CC$, define the pencil of operators
\[
  \mathcal{P}(\lambda):=\dot\X-\lambda \X.
\]
Since the codomain is finite-dimensional, $\operatorname{rank}(\mathcal{P}(\lambda)):=\dim(\operatorname{range}(\mathcal{P}(\lambda)))\le n$, and \textit{full rank} means surjectivity onto $\CC^n$.
For $\varphi\in L^2(0,T)$ and $w\in\CC^n$,
\[
  \angl \X(\varphi),w\angr_{\CC^n}
  =\Big(\int_0^T x(t)\varphi(t)\,\d t\Big)^*w
  =\int_0^T \overline{\varphi(t)}\,x(t)^*w\,\d t
  =\angl \varphi,\,x(\cdot)^*w\angr_{L^2(0,T)}.
\]
Repeating the same process for $\dot\X$ yields
\begin{equation*}
  (\X^*w)(t)=x(t)^*w,\qquad (\dot\X^*w)(t)=\dot x(t)^*w\qquad\text{in }L^2(0,T),
\end{equation*}
Therefore, for $w\in\CC^n$,
\[
  \mathcal{P}(\lambda)\mathcal{P}(\lambda)^*w
  =\mathcal{P}(\lambda)\big(\dot\X^*w-\overline{\lambda}\X^*w\big)
  =\int_0^T m_\lambda(t)\,m_\lambda(t)^*w\,\d t
  =\mat{G}_\lambda(u)\,w.
\]
Hence,
\begin{equation}\label{eq:hautus-operator-gram-identity}
  \mathcal{P}(\lambda)\mathcal{P}(\lambda)^* = \mat{G}_\lambda(u)\qquad\text{as operators }\CC^n\to\CC^n.
\end{equation}
Since $\mathcal{P}(\lambda):L^2(0,T)\to\CC^n$ has finite-dimensional codomain, it is surjective if and only if
$\mathcal{P}(\lambda)\mathcal{P}(\lambda)^*$ is invertible on $\CC^n$.
By \eqref{eq:hautus-operator-gram-identity}, for every $\lambda\in\CC$,
\begin{equation}\label{eq:hautus-operator-full-rank}
  \operatorname{rank}(\mathcal{P}(\lambda))=n
  \quad\Leftrightarrow\quad
  \mat{G}_\lambda(u)\ \text{is invertible}.
\end{equation}
The next result shows that, under a mild nondegeneracy assumption, rank failure can only occur at finitely many ``candidate'' values of $\lambda$.

\begin{thm}[Finite candidate set for $\lambda\in \CC$]\label{thm:hautus-operator-finite-lambda}
  Assume $\operatorname{rank}(\X)=n$, equivalently
  \[
    \X\X^* = \int_0^T x(t)x(t)^*\,\d t\in\CC^{n\times n}\quad\text{is invertible}.
  \]
  This is a data-richness condition: it requires, in particular, that the trajectory does not remain in a strict subspace of $\R^n$ on $[0,T]$.
  Define
  \[
    \mat{K}:=(\X\X^*)^{-1}\X\dot\X^*\in\CC^{n\times n}.
  \]
  Then for every $\lambda\in\CC$,
  \[
    \operatorname{rank}(\mathcal{P}(\lambda))<n
    \quad\Longrightarrow\quad
    \lambda\in\sigma(\mat{K}).
  \]
  In particular, the set of $\lambda$ for which $\operatorname{rank}(\mathcal{P}(\lambda))<n$ is contained in $\sigma(\mat{K})$, which has at most $n$ elements.
  Moreover, in terms of time-domain moments,
  \[
    \mat{K}
    =\Big(\int_0^T x(t)x(t)^*\,\d t\Big)^{-1}\Big(\int_0^T x(t)\dot x(t)^*\,\d t\Big).
  \]
\end{thm}
\begin{proof}
  Fix $\lambda\in\CC$ and assume $\operatorname{rank}(\mathcal{P}(\lambda))<n$.
  Since the codomain is $\CC^n$, the left nullspace is nontrivial, so there exists $0\neq w\in\CC^n$ with
  $\mathcal{P}(\lambda)^*w=0$, i.e.\ $\dot\X^*w=\overline{\lambda}\X^*w$.
  Left-multiply by $(\X\X^*)^{-1}\X$ to obtain
  \[
    \mat{K}w
    =(\X\X^*)^{-1}\X\dot\X^*w
    =\overline{\lambda}\,(\X\X^*)^{-1}\X\X^*w
    =\overline{\lambda}\,w,
  \]
  so $\overline{\lambda}\in\sigma(\mat{K})$.
  Since $x$ is real-valued, the moments defining $\mat{K}$ are real and hence $\sigma(\mat{K})$ is closed under complex conjugation, which yields $\lambda\in\sigma(\mat{K})$.
\end{proof}

\begin{cor}[Finite checking]\label{cor:hautus-operator-finite-checking}
  Under the assumptions of Theorem~\ref{thm:hautus-operator-finite-lambda}, if
  \[
    \operatorname{rank}(\mathcal{P}(\lambda))=n\qquad\text{for all }\lambda\in\sigma(\mat{K}),
  \]
  then $\operatorname{rank}(\mathcal{P}(\lambda))=n$ for all $\lambda\in\CC$.
\end{cor}
\begin{proof}
  If there existed $\lambda_0\in\CC$ with $\operatorname{rank}(\mathcal{P}(\lambda_0))<n$, then
  Theorem~\ref{thm:hautus-operator-finite-lambda} would imply $\lambda_0\in\sigma(\mat{K})$, contradicting the hypothesis.
\end{proof}

\begin{lem}[A quantitative lower bound for $\sigma_{\min}(\mat{G}_\lambda(u))$ via $\mat{K}$]\label{lem:hautus-operator-margin-bound}
  Assume $\operatorname{rank}(\X)=n$ and let $\mat{K}$ be as in Theorem~\ref{thm:hautus-operator-finite-lambda}.
  Then for every $\lambda\in\CC$,
  \[
    \sigma_{\min}\!\big(\mat{G}_\lambda(u)\big)
    \ge
    \frac{\sigma_{\min}(\mat{K}-\overline{\lambda}\,\mat{I})^2}{\|(\X\X^*)^{-1}\X\|^2}.
  \]
  In particular, if $\lambda\notin\sigma(\mat{K})$, then $\mat{G}_\lambda(u)$ is invertible and $\sigma_{\min}(\mat{G}_\lambda(u))>0$.
\end{lem}
\begin{proof}
  Fix $w\in\CC^n$.
  Since $w^*(\dot\X-\lambda\X)$ is a bounded linear functional on $L^2(0,T)$, we have
  \[
    \big\|w^*(\dot\X-\lambda\X)\big\|
    =\big\|(\dot\X^*-\overline{\lambda}\,\X^*)w\big\|_{L^2(0,T)}.
  \]
  Moreover,
  \[
    (\mat{K}-\overline{\lambda}\,\mat{I})w
    =(\X\X^*)^{-1}\X(\dot\X^*-\overline{\lambda}\,\X^*)w,
  \]
  hence
  \[
    \|(\mat{K}-\overline{\lambda}\,\mat{I})w\|
    \le \|(\X\X^*)^{-1}\X\|\,\big\|(\dot\X^*-\overline{\lambda}\,\X^*)w\big\|_{L^2(0,T)}.
  \]
  Using \eqref{eq:hautus-operator-gram-identity}, $\|(\dot\X^*-\overline{\lambda}\,\X^*)w\|_{L^2(0,T)}^2=w^*\mat{G}_\lambda(u)w$, so
  \[
    w^*\mat{G}_\lambda(u)w \ge \frac{\|(\mat{K}-\overline{\lambda}\,\mat{I})w\|^2}{\|(\X\X^*)^{-1}\X\|^2}.
  \]
  Taking the minimum over $\|w\|_2=1$ yields the claimed bound.
  The final claim follows since $\sigma_{\min}(\mat{K}-\overline{\lambda}\,\mat{I})>0$ whenever $\lambda\notin\sigma(\mat{K})$.
\end{proof}

Consequently, for rank certification it is enough to check the finitely many candidates $\sigma(\mat{K})$.
  \begin{rmk}[Frequency-domain calculation]\label{rmk:frequency-domain-candidate-lambda}
	  The matrix $\mat{K}$ in Theorem~\ref{thm:hautus-operator-finite-lambda} can be computed from the Fourier transforms of $x$ and $\dot x$ as
	  \[
	    \mat{K}
	    =\Big(\int_{\R} \widehat x(\ii\omega)\widehat x(\ii\omega)^*\,\frac{\d\omega}{2\pi}\Big)^{-1}
	    \Big(\int_{\R} \widehat x(\ii\omega)\widehat{\dot x}(\ii\omega)^*\,\frac{\d\omega}{2\pi}\Big),
	  \]
	  where we know that $\widehat{\dot x}(\ii\omega) = x(T)e^{-\ii\omega T} - x(0) + \ii\omega \widehat{x}(\ii\omega)$.

\end{rmk}




\subsection{Best conditioning of control inputs}

The data-driven Hautus margins in Corollary~\ref{cor:hautus-cross-moment-test} are controlled (up to the model-dependent factor $\sigma_{\min}(\mat{P}_\lambda)$) by the smallest singular value of the stacked Gramian $\mat{S}_Z(u)$.
Since $\mat{S}_Z(u)$ depends on the unknown response $x(\cdot)$, a natural model-agnostic surrogate is to ensure that the \emph{input} Gramian is well conditioned, so that the input directions are persistently excited and the inversion of $\mat{S}_Z(u)$ in \eqref{eq:hautus-cross-moment-G-from-H} is numerically stable.
Under an $L^2$ energy budget, the best possible conditioning corresponds to spreading the energy isotropically across the $m$ input channels.

\begin{thm}[Best conditioning of the input Gramian under $\|u\|_{L^2}\leq 1$]\label{thm:hautus-isotropic-input}
  Define the input Gramian
  \[
    \mat{S}_U(u):=\int_0^T u(t)u(t)^\top\,\d t \in \R^{m\times m}.
  \]
  If $\|u\|_{L^2(0,T)}^2\leq 1$, then
  \[
    \lambda_{\min}(\mat{S}_U(u)) \le \frac{1}{m}.
  \]
  Moreover, there exist $u$ with $\|u\|_{L^2(0,T)}\leq 1$ such that $\mat{S}_U(u)=\frac{1}{m}\mat{I}_m$. In particular, the upper bound is tight.
\end{thm}
\begin{proof}
  Since $\mat{S}_U(u)\succeq 0$, we have $\lambda_{\min}(\mat{S}_U(u))\le \tfrac{1}{m}\operatorname{tr}(\mat{S}_U(u))$.
  Moreover,
  \[
    \operatorname{tr}(\mat{S}_U(u))
    =\int_0^T \operatorname{tr}\!\big(u(t)u(t)^\top\big)\,\d t
    =\int_0^T \|u(t)\|_2^2\,\d t
    =\|u\|_{L^2(0,T)}^2
    \le 1,
  \]
  which gives the upper bound.
  For achievability, pick an orthonormal set $\{\varphi_i\}_{i=1}^m\subset L^2(0,T)$ and define
  $u(t):=\frac{1}{\sqrt m}[\varphi_1(t)\ \cdots\ \varphi_m(t)]^\top$; then $\mat{S}_U(u)=\frac{1}{m}\mat{I}_m$.
\end{proof}

\begin{rmk}
The matrix $\mat{S}_U(u)$ is a principal submatrix of $\mat{S}_Z(u)$, hence
\[
  \sigma_{\min}(\mat{S}_Z(u))\le \sigma_{\min}(\mat{S}_U(u)).
\]
Thus, even though $\sigma_{\min}(\mat{S}_Z(u))$ depends on the state-response, and therefore on $(\mat{A},\mat{B})$ and the initial condition,
choosing inputs with well-conditioned $\mat{S}_U(u)$ is a natural baseline when seeking a large $\sigma_{\min}(\mat{S}_Z(u))$ without model knowledge.
\end{rmk}

\subsection{Best conditioning under an \texorpdfstring{$H^1$}{H1} budget}
\label{subsec:hautus-best-conditioning-h1}

In applications one may also constrain input \emph{smoothness}, for instance by an $H^1$ budget
\[
  \|u\|_{H^1(0,T)}^2:=\int_0^T \big(\|u(t)\|_2^2+\|\dot u(t)\|_2^2\big)\,\d t \le 1.
\]
This penalizes high-frequency excitation and therefore reduces the best achievable isotropic conditioning compared to the $L^2$-only case.

\begin{thm}[$H^1$-budget isotropic input]\label{thm:hautus-isotropic-input-h1}
  Let $u\in H^1(0,T;\R^m)$ satisfy $\|u\|_{H^1(0,T)}\le 1$, and define $\mat{S}_U(u):=\int_0^T u(t)u(t)^\top\,\d t$.
  Then
  \[
    \lambda_{\min}(\mat{S}_U(u))
    \le
    \frac{1}{\displaystyle \sum_{k=0}^{m-1}\Big(1+\big(\tfrac{k\pi}{T}\big)^2\Big)}
    =
    \frac{1}{\displaystyle m+\frac{\pi^2}{T^2}\cdot\frac{(m-1)m(2m-1)}{6}}.
  \]
  Moreover, the bound is tight: if $\{\psi_k\}_{k\ge 0}$ are the Neumann eigenfunctions on $[0,T]$ given by
  \[
    \psi_0(t):=\frac{1}{\sqrt{T}},
    \qquad
    \psi_k(t):=\sqrt{\frac{2}{T}}\cos\!\Big(\frac{k\pi t}{T}\Big)\ \ (k\ge 1),
  \]
  and $Q\in\R^{m\times m}$ is orthogonal, then with
  \[
    \alpha:=\Big(\sum_{k=0}^{m-1}\big(1+(\tfrac{k\pi}{T})^2\big)\Big)^{-1},
    \qquad
    u(t):=\sqrt{\alpha}\,Q\begin{bmatrix}\psi_0(t)\\ \vdots\\ \psi_{m-1}(t)\end{bmatrix},
  \]
  one has $\|u\|_{H^1(0,T)}^2=1$ and $\mat{S}_U(u)=\alpha\,\mat{I}_m$.
\end{thm}
\begin{proof}
  Expand $u$ in the orthonormal Neumann basis $\{\psi_k\}_{k\ge 0}$ as $u(t)=\sum_{k\ge 0}\psi_k(t)a_k$ with coefficients $a_k\in\R^m$, so that
  \[
    \mat{S}_U(u)=\sum_{k\ge 0} a_k a_k^\top,
    \qquad
    \|u\|_{H^1(0,T)}^2=\sum_{k\ge 0}\Big(1+\big(\tfrac{k\pi}{T}\big)^2\Big)\|a_k\|_2^2.
  \]
  Let $W:=\operatorname{diag}(w_0,w_1,\dots)$ with $w_k:=1+(\tfrac{k\pi}{T})^2$, and define $A:=[a_0\ a_1\ \cdots]$, so that $\mat{S}_U(u)=AA^\top$ and $\|u\|_{H^1(0,T)}^2=\operatorname{tr}(A W A^\top)$.
  Write $A=\mat{S}_U(u)^{1/2}R$ where $R$ has orthonormal rows ($RR^\top=\mat{I}_m$), and set $\Pi:=R^\top R$, a rank-$m$ orthogonal projector.
  Then
  \begin{align*}
    \|u\|_{H^1(0,T)}^2
    &=\operatorname{tr}\!\big(\mat{S}_U(u)^{1/2}RWR^\top \mat{S}_U(u)^{1/2}\big)\\
    &=\operatorname{tr}\!\big(\mat{S}_U(u)\,RWR^\top\big)\\
    &\ge \lambda_{\min}(\mat{S}_U(u))\,\operatorname{tr}(RWR^\top)\\
    &= \lambda_{\min}(\mat{S}_U(u))\,\operatorname{tr}(W\Pi).
  \end{align*}
  Since $W$ is diagonal with nondecreasing entries, the minimum of $\operatorname{tr}(W\Pi)$ over rank-$m$ projectors $\Pi$ equals $\sum_{k=0}^{m-1}w_k$, attained by projecting onto $\operatorname{span}\{\psi_0,\dots,\psi_{m-1}\}$.
  Using $\|u\|_{H^1(0,T)}^2\le 1$ gives the stated upper bound on $\lambda_{\min}(\mat{S}_U(u))$.
  The construction with the first $m$ Neumann modes and orthogonal $Q$ yields $\mat{S}_U(u)=\alpha \mat{I}_m$ and saturates $\|u\|_{H^1(0,T)}^2=1$.
\end{proof}

\begin{rmk}
As $T\to\infty$ the derivative penalty vanishes and $\alpha\to 1/m$, recovering the $L^2$-budget optimum in Theorem~\ref{thm:hautus-isotropic-input}.
For short horizons (or large $m$), the optimal $H^1$-budget design suppresses high-frequency components and yields a smaller isotropic eigenvalue $\alpha$.
\end{rmk}
