\section{Problem Statement: Data-Driven Controllability Certification}\label{sec:problem}


% Given an initial condition $x_0\in\R^n$, the state trajectory admits the closed-form solution
% \begin{equation}\label{eq:solution}
%   x(t) = e^{\mat{A}t}x_0 + \int_0^t e^{\mat{A}(t-\tau)}\mat{B}\, u(\tau) \, \d\tau.
% \end{equation}
% A fundamental property of the system is \textbf{controllability}: the ability to steer the state to any point in $\R^n$ using an appropriate input signal.
% Our objective is to design input signals $u(t)$ such that the observed trajectories reveal the controllability rank.


% A natural route to certifying controllability from data is via terminal-state information under structural assumptions, such as a fixed initial condition and structured input families.
% In this section, we develop an alternative approach based on rank conditions that are equivalent to controllability and stabilizability.

% Recall that for the continuous-time LTI system~\eqref{eq:lti}, the classical Hautus (Popov--Belevitch--Hautus, PBH) test \cite[Theorem~3.13]{trentelmanControlTheoryLinear2001} characterizes controllability and stabilizability
% Here we state a continuous-time version based on time-domain moments of the state and input signals.
We assume access to $u(\cdot)$ and the resulting state $x(\cdot)$ on a finite horizon $[0,T]$.
When $\dot x$ is not directly available or is too noisy to estimate reliably, we rely on the cross-moment formulation in Section~\ref{sec:stochastic}, which only uses increments of $x$ in the stochastic setting and avoids forming $\dot x$ in the deterministic setting.



\subsection{Noise-free cross-moment formulation}
\label{subsec:hautus-time-domain}

We consider the continuous-time Linear Time-Invariant (LTI) system
\begin{equation}\label{eq:lti}
  \begin{aligned}
     & \dot x(t) = \mat{A} x(t) + \mat{B} u(t), \\
     & x(0) = x_0,
  \end{aligned}
\end{equation}
where the state $x(t)\in\R^n$, the input $u(t)\in\R^m$, and the system matrices $\mat{A}\in \mathbb{R}^{n \times n}$ and $\mat{B} \in \mathbb{R}^{n \times m}$ are unknown.

For input design it is convenient to work with a time-domain moment formulation based on the residual and the stacked state--input signal.
Fix a horizon $T>0$ and let $u\in L^2(0,T;\R^m)$ be an input generating an absolutely continuous state trajectory $x:[0,T]\to\R^n$ with $x,\dot x\in L^2(0,T;\R^n)$.
For $\lambda\in\CC$ define the cross-moment
\[
  \mat{H}_\lambda(T):=\int_0^T (\dot x(t)-\lambda x(t))z(t)^\top\,\d t\in\CC^{n\times (n+m)}.
\]
where $z(t):=[x(t);u(t)]\in\R^{n+m}$ is the stacked state-input vector. Define the stacked Gramian
\[
  \mat{S}_Z(T):=\int_0^T z(t)z(t)^\top\,\d t\in\R^{(n+m)\times(n+m)}.
\]
Finally, define the Hautus matrix
\[
  \mat{P}_\lambda := \begin{bmatrix}\mat{A}-\lambda \mat{I} & \mat{B}\end{bmatrix}\in\CC^{n\times(n+m)}.
\]
Note that $\mat{S}_Z(T)\succeq 0$ by construction. Moreover, for every admissible input $u$,
\begin{equation}\label{eq:hautus-continuous-factorization}
  \mat{H}_\lambda(T)=\mat{P}_\lambda \mat{S}_Z(T).
\end{equation}
If $\mat{S}_Z(T)$ is invertible, then right-multiplication by $\mat{S}_Z(T)$ preserves row rank and yields the continuous-time Hautus test.


\begin{thm}[Continuous Hautus Test]\label{thm:hautus-margin-necessary}
  If there exists $u$ such that $\operatorname{rank}(\mat{H}_\lambda(T))=n$ for all $\lambda\in\CC$, then $(\mat{A},\mat{B})$ is controllable.
  Moreover, if $\mat{S}_Z(T)$ is invertible, then the converse holds
  \begin{align*}
    (\mat{A},\mat{B}) \text{ is controllable}\quad & \Leftrightarrow\quad
    \operatorname{rank}(\mat{H}_\lambda(T))=n \text{ for all } \lambda\in\CC, \\
    (\mat{A},\mat{B}) \text{ is stabilizable}\quad & \Leftrightarrow\quad
    \operatorname{rank}(\mat{H}_\lambda(T))=n \text{ for all } \lambda\in\CC \text{ with } \Re(\lambda)\ge 0.
  \end{align*}
\end{thm}
\begin{proof}
  See Appendix~\ref{app:proof:hautus-margin-necessary}.
\end{proof}


This result justifies the use of the margin $\sigma_{\min}(\mat{H}_\lambda(T))$ as a data-driven certificate of controllability and stabilizability. Moreover, $\mat{S}_Z(T)$ plays a key role in the conditioning of the test (see Section~\ref{sec:stochastic}). Therefore, input design should seek to maximize $\sigma_{\min}(\mat{S}_Z(T))$ under suitable constraints.


\subsection{Best conditioning of control inputs}
\label{subsec:hautus-best-conditioning}

The singular-value margins of the data-driven Hautus test are controlled---up to the model-dependent factor $\sigma_{\min}(\mat{P}_\lambda)$---by the smallest singular value of the stacked Gramian $\mat{S}_Z(T)$.
Since $\mat{S}_Z(T)$ depends on the (unknown) response $x(\cdot)$, a natural model-agnostic surrogate is to ensure that the \emph{input} Gramian is well conditioned, so that the input directions are persistently excited and the inversion of $\mat{S}_Z(T)$ is numerically stable.
Define the input Gramian
\[
  \mat{S}_U(u):=\int_0^T u(t)u(t)^\top\,\d t \in \R^{m\times m}.
\]
\begin{rmk}
  The matrix $\mat{S}_U(u)$ is a principal submatrix of $\mat{S}_Z(T)$, hence
  \[
    \sigma_{\min}(\mat{S}_Z(T))\le \sigma_{\min}(\mat{S}_U(u)).
  \]
  Thus, even though $\sigma_{\min}(\mat{S}_Z(T))$ depends on the state response, and therefore on $(\mat{A},\mat{B})$ and the initial condition,
choosing inputs with well-conditioned $\mat{S}_U(u)$ is a natural baseline when seeking a large $\sigma_{\min}(\mat{S}_Z(T))$ without model knowledge. This idea motivates the input designs in the next results.
\end{rmk}



Under an $L^2$ energy budget, the best possible conditioning corresponds to spreading the energy isotropically across the $m$ input channels.


\begin{prop}[Best conditioning under $\|u\|_{L^2}\leq 1$]\label{prop:hautus-isotropic-input}
  If $\|u\|_{L^2(0,T)}^2\leq 1$, then
  \[
    \lambda_{\min}(\mat{S}_U(u)) \le \frac{1}{m}.
  \]
  Moreover, there exist $u$ with $\|u\|_{L^2(0,T)}\leq 1$ such that $\mat{S}_U(u)=\frac{1}{m}\mat{I}_m$. 
\end{prop}
\begin{proof}
  See Appendix~\ref{app:proof:hautus-isotropic-input}.
\end{proof}

In applications one may also constrain input \emph{smoothness}, for instance by an $H^1$ budget
\[
  \|u\|_{H^1(0,T)}^2:=\int_0^T \big(\|u(t)\|_2^2+\|\dot u(t)\|_2^2\big)\,\d t \le 1.
\]
This penalizes high-frequency excitation and therefore reduces the best achievable isotropic conditioning compared to the $L^2$-only case.

\begin{prop}[Best conditioning under $\|u\|_{H^1}\leq 1$]\label{prop:hautus-isotropic-input-h1}
  Let $u\in H^1(0,T;\R^m)$ satisfy $\|u\|_{H^1(0,T)}\le 1$, and define $\mat{S}_U(u):=\int_0^T u(t)u(t)^\top\,\d t$.
  Then
  \[
    \lambda_{\min}(\mat{S}_U(u))
    \le
    \frac{1}{\displaystyle \sum_{k=0}^{m-1}\Big(1+\big(\tfrac{k\pi}{T}\big)^2\Big)}
    =
    \frac{1}{\displaystyle m+\frac{\pi^2}{T^2}\cdot\frac{(m-1)m(2m-1)}{6}}.
  \]
  Moreover, the bound is tight: if $\{\psi_k\}_{k\ge 0}$ are the Neumann eigenfunctions on $[0,T]$ given by
  \[
    \psi_0(t):=\frac{1}{\sqrt{T}},
    \qquad
    \psi_k(t):=\sqrt{\frac{2}{T}}\cos\!\Big(\frac{k\pi t}{T}\Big)\ \ (k\ge 1),
  \]
  and $Q\in\R^{m\times m}$ is orthogonal, then with
  \[
    u(t)=\sqrt{\alpha}\,Q\begin{bmatrix}\psi_0(t)\\ \vdots\\ \psi_{m-1}(t)\end{bmatrix}, \quad \text{where}\quad
    \alpha:=\Big(\sum_{k=0}^{m-1}\big(1+(\tfrac{k\pi}{T})^2\big)\Big)^{-1}
  \]
  one has $\|u\|_{H^1(0,T)}^2=1$ and $\mat{S}_U(u)=\alpha\,\mat{I}_m$.
\end{prop}
\begin{proof}
  See Appendix~\ref{app:proof:hautus-isotropic-input-h1}.
\end{proof}

\begin{rmk}
  As $T\to\infty$ the derivative penalty vanishes and $\alpha\to 1/m$, recovering the $L^2$-budget optimum in Proposition~\ref{prop:hautus-isotropic-input}.
  For short horizons (or large $m$), the optimal $H^1$-budget design suppresses high-frequency components and yields a smaller isotropic eigenvalue $\alpha$.
\end{rmk}






\subsection{An operator formulation and finitely many candidate \texorpdfstring{$\lambda$}{lambda}}
\label{subsec:hautus-operator}
The main inconvenience of Theorem~\ref{thm:hautus-margin-necessary} is that the rank condition must hold for all $\lambda\in\CC$.
To address this, we now develop an operator formulation that allows us to identify finitely many candidate $\lambda$ where rank failure can occur.
%
Let $x:[0,T]\to\R^n$ be absolutely continuous with $x,\dot x\in L^2(0,T;\R^n)$ and define operators
\[
  \X,\dot\X:L^2(0,T)\to\CC^n,\qquad
  \X(\varphi):=\int_0^T x(t)\varphi(t)\,\d t,\quad
  \dot\X(\varphi):=\int_0^T \dot x(t)\varphi(t)\,\d t.
\]
For $\varphi\in L^2(0,T)$ and $w\in\CC^n$,
\[
  \angl \X(\varphi),w\angr_{\CC^n}
  =\Big(\int_0^T x(t)\varphi(t)\,\d t\Big)^*w
  =\int_0^T \overline{\varphi(t)}\,x(t)^*w\,\d t
  =\angl \varphi,\,x(\cdot)^*w\angr_{L^2(0,T)}.
\]
Repeating the same process for $\dot\X$ yields
\begin{equation*}
  (\X^*w)(t)=x(t)^*w,\qquad (\dot\X^*w)(t)=\dot x(t)^*w\qquad\text{in }L^2(0,T),
\end{equation*}
For $\lambda\in\CC$, define the pencil of operators
\[
  \mathcal{P}(\lambda):=\dot\X-\lambda \X.
\]
Since the codomain is finite-dimensional, $\operatorname{rank}(\mathcal{P}(\lambda)):=\dim(\operatorname{range}(\mathcal{P}(\lambda)))\le n$, and \textit{full rank} means surjectivity onto $\CC^n$.
Therefore, for $w\in\CC^n$,
\[
  \mathcal{P}(\lambda)\mathcal{P}(\lambda)^*w
  =\mathcal{P}(\lambda)\big(\dot\X^*w-\overline{\lambda}\X^*w\big)
  =\int_0^T \big(\dot x(t)-\lambda x(t)\big)\big(\dot x(t)-\lambda x(t)\big)^*w\,\d t
  =:\mat{G}_\lambda(u)\,w.
\]
Hence,
\begin{equation}\label{eq:hautus-operator-gram-identity}
  \mathcal{P}(\lambda)\mathcal{P}(\lambda)^* = \mat{G}_\lambda(u)\qquad\text{as operators }\CC^n\to\CC^n.
\end{equation}
Since $\mathcal{P}(\lambda):L^2(0,T)\to\CC^n$ has finite-dimensional codomain, it is surjective if and only if
$\mathcal{P}(\lambda)\mathcal{P}(\lambda)^*$ is invertible on $\CC^n$.
By \eqref{eq:hautus-operator-gram-identity}, for every $\lambda\in\CC$,
\begin{equation}\label{eq:hautus-operator-full-rank}
  \operatorname{rank}(\mathcal{P}(\lambda))=n
  \quad\Leftrightarrow\quad
  \mat{G}_\lambda(u)\ \text{is invertible}.
\end{equation}
When $\mat{S}_Z(T)\succ 0$, the cross-moment representation further gives
\begin{equation}\label{eq:hautus-operator-G-from-H}
  \mat{G}_\lambda(u)=\mat{H}_\lambda(T)\mat{S}_Z(T)^{-1}\mat{H}_\lambda(T)^*,
\end{equation}
so $\mat{G}_\lambda(u)$ is invertible if and only if $\mat{H}_\lambda(T)$ has full row rank.
Thus, in the data-driven Hautus test it suffices to understand for which $\lambda$ the matrix $\mat{H}_\lambda(T)$ can lose rank.
The next result shows that, under a mild nondegeneracy assumption, rank failure can only occur at finitely many \emph{candidate} values of $\lambda$.

\begin{thm}[Finite candidate set for $\lambda\in \CC$]\label{thm:hautus-operator-finite-lambda}
  Assume $\operatorname{rank}(\X)=n$, equivalently
  \[
    \X\X^* = \int_0^T x(t)x(t)^*\,\d t\in\CC^{n\times n}\quad\text{is invertible}.
  \]
  This is a data-richness condition: it requires, in particular, that the trajectory does not remain in a strict subspace of $\R^n$ on $[0,T]$.
  Define
  \[
    \mat{K}:=(\X\X^*)^{-1}\X\dot\X^*=\Big(\int_0^T x(t)x(t)^*\,\d t\Big)^{-1}\Big(\int_0^T x(t)\dot x(t)^*\,\d t\Big)\in\CC^{n\times n}.
  \]
  Then for every $\lambda\in\CC$,
  \[
    \operatorname{rank}(\mathcal{P}(\lambda))<n
    \quad\Longrightarrow\quad
    \lambda\in\sigma(\mat{K}).
  \]
  In particular, the set of $\lambda$ for which $\operatorname{rank}(\mathcal{P}(\lambda))<n$ is contained in $\sigma(\mat{K})$.
\end{thm}
\begin{proof}
  See Appendix~\ref{app:proof:hautus-operator-finite-lambda}.
\end{proof}


Suppose there existed $\lambda_0\in\CC$ with $\operatorname{rank}\big(\mat{H}_{\lambda_0}(T)\big)<n$.
Since $\mat{S}_Z(T)\succ 0$, the matrix \eqref{eq:hautus-operator-G-from-H}
is singular, hence \eqref{eq:hautus-operator-full-rank} implies $\operatorname{rank}(\mathcal{P}(\lambda_0))<n$.
Therefore, the above theorem yields $\lambda_0\in\sigma(\mat{K})$, which implies the following result.

\begin{cor}[Finite checking for the data-driven test]\label{cor:hautus-finite-checking-H}
  Assume $\operatorname{rank}(\X)=n$ and $\mat{S}_Z(T)\succ 0$, and let $\mat{K}$ be as in Theorem~\ref{thm:hautus-operator-finite-lambda}.
  Define the candidate set $\Lambda:=\sigma(\mat{K})$, hence $|\Lambda|\le n$.
  If
  \[
    \operatorname{rank}\big(\mat{H}_\lambda(T)\big)=n\qquad\text{for all }\lambda\in\Lambda,
  \]
  then $\operatorname{rank}\big(\mat{H}_\lambda(T)\big)=n$ for all $\lambda\in\CC$.
\end{cor}

\begin{lem}[A quantitative lower bound for $\sigma_{\min}(\mat{H}_\lambda(T))$ via $\mat{K}$]\label{lem:hautus-operator-margin-bound}
  Assume $\operatorname{rank}(\X)=n$, $\mat{S}_Z(T)\succ 0$, and let $\mat{K}$ be as in Theorem~\ref{thm:hautus-operator-finite-lambda}.
  Then for every $\lambda\in\CC$,
  \[
    \sigma_{\min}\!\big(\mat{H}_\lambda(T)\big)
    \ge
    \sqrt{\sigma_{\min}\!\big(\mat{S}_Z(T)\big)}\,
    \frac{\sigma_{\min}(\mat{K}-\overline{\lambda}\,\mat{I})}{\|(\X\X^*)^{-1}\X\|}.
  \]
  In particular, if $\lambda\notin\sigma(\mat{K})$, then $\mat{H}_\lambda(T)$ has full row rank.
\end{lem}
\begin{proof}
  See Appendix~\ref{app:proof:hautus-operator-margin-bound}.
\end{proof}










